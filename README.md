# INTELONEAPI
INTEL ONE API HACKATHON


Interactive Avatar with Emotion Recognition

This project presents an interactive avatar system that recognizes user emotions based on voice and facial expressions. The avatar interacts with the user in real-time, reflecting their emotional state through its expressions.
Features:

Emotion Recognition: The system utilizes Intel OneAPI tools for both voice and facial emotion recognition. Through Intel OpenVINO toolkit, facial expressions are analyzed, while Intel Deep Learning tools process voice input to determine the user's emotional state accurately.
  
Real-Time Interaction: The avatar responds in real-time to the user's emotions, providing an interactive and engaging experience.

Intel Technologies: Leveraging the power of Intel RealSense for facial expression detection, the system captures the user's facial movements accurately. Furthermore, Intel OpenVINO toolkit enables efficient inference of emotion recognition models, ensuring smooth performance.

User-Friendly Interface: The avatar is displayed in a user-friendly interface, allowing users to easily interact with and observe the avatar's responses.

Tools Used:

Intel RealSense: Used for capturing the user's facial expressions in real-time.
  
Intel OpenVINO Toolkit: Employed for efficient inference of emotion recognition models, enabling real-time analysis of facial expressions.

Intel Deep Learning Tools: Utilized for processing voice input and determining the user's emotional state accurately.

Usage:

1. Ensure you have the necessary dependencies installed, including Intel RealSense SDK and Intel OpenVINO toolkit.
  
2. Run the main script to start the interactive avatar system.
  
3. The system will capture the user's facial expressions and voice input, analyzing them in real-time to determine the user's emotional state.
  
4. The avatar will respond dynamically, reflecting the user's emotions through its expressions.



