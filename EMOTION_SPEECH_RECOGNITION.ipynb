{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bcf88-5bae-4ca1-8dda-89579b9732f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cfd44-38be-47e6-8b92-a760f368b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenVINO\n",
    "ie = IECore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e0a26-64a2-4618-9bd2-bcdcf7d9626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE MODEL\n",
    "emotion_net = ie.read_network(model='C:\\llm\\model.xml', weights='C:\\llm\\emotion_detection_model.bin')\n",
    "emotion_exec_net = ie.load_network(network=emotion_net, device_name='CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57733c05-20fa-437b-84d5-0320cbf18e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944da31-7071-44e0-9dc0-079771b3f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to infer emotion from audio\n",
    "def infer_emotion(audio_data):\n",
    "\n",
    "    output = emotion_exec_net.infer(inputs={'input_blob_name': audio_data})\n",
    "\n",
    "    emotion_index = np.argmax(output['output_blob_name'])\n",
    "    emotion = emotion_labels[emotion_index]\n",
    "\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a1864-a745-4c1a-9eb2-d5544fb8c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    # Read input \n",
    "    audio_file = 'path_to_input_audio_file.wav'\n",
    "    audio_data = preprocess_audio(audio_file)\n",
    "\n",
    "    # Infer emotion from audio\n",
    "    emotion = infer_emotion(audio_data)\n",
    "\n",
    "    # Output \n",
    "    print(\"Detected emotion:\", emotion)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8544b0-e958-469a-9e98-d1e57d979672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6485b-24dc-4dbe-93d6-da9df8090df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IntelÂ® oneAPI 2024)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python-2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
